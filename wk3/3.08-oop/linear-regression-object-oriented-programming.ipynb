{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Object-Oriented Programming: Coding a Linear Regression Class\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Describe the fundamentals of object-oriented programming in Python\n",
    "- Implement classes in Python 3.\n",
    "- Apply object-oriented programming concepts to build a linear regression class by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "\n",
    "- [Review the Linear Algebra Derivation of Coefficients for MLR](#review-mlr)\n",
    "- [Load the Simple Housing Data](#load-data)\n",
    "- [Classes and Objects](#classes-objects)\n",
    "- [Coding our Own `LinearRegression` Class](#coding-lr)\n",
    "    - [Starting a Basic Python Class](#starting-class)\n",
    "    - [Adding a Class Function](#class-function)\n",
    "    - [Assigning Attributes During Instantiation](#init-args)\n",
    "    - [Add Another Function to Add an Intercept](#intercept-adder)\n",
    "    - [Instantiate the Class](#instantiate)\n",
    "    - [Add a Predict Function](#predict)\n",
    "    - [Add a Score Function](#score)\n",
    "- [Verify Your Class Against the Scikit-Learn Implementation](#verify)\n",
    "- [Inspecting a Class](#inspection)\n",
    "- [Some Special Class Methods](#special)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review-mlr'></a>\n",
    "\n",
    "## Review: Solving for the Coefficients That Minimize the Loss\n",
    "\n",
    "---\n",
    "\n",
    "### The \"Least Squares\" Solution to Linear Regression\n",
    "\n",
    "**Step 1:** With target vector $y$ and prediction matrix $X$, we can formulate a regression as:\n",
    "\n",
    "### $$ y = \\beta X + \\epsilon $$\n",
    "\n",
    "Where $\\beta$ is our vector of coefficients and $\\epsilon$ is our vector of errors, or residuals.\n",
    "\n",
    "**Step 2:** Equivalently, we can formulate this as a calculation of the residuals:\n",
    "\n",
    "### $$ \\epsilon = \\beta X - y $$\n",
    "\n",
    "*Our goal is to minimize the sum of the squared residuals.* This is also known as the \"least squares loss function.\" \n",
    "\n",
    "**Step 3:** Solve for the sum of the squared residuals on the left side of the equation. Recall that the vector of errors are equivalent to the residuals. The sum of the squared residuals is represented as the dot product of the vector of residuals.\n",
    "\n",
    "### $$ \\sum_{i=1}^n \\epsilon_i^2 = \n",
    "\\left[\\begin{array}{cc}\n",
    "\\epsilon_1 \\cdots \\epsilon_n\n",
    "\\end{array}\\right] \n",
    "\\left[\\begin{array}{cc}\n",
    "\\epsilon_1 \\\\ \\cdots \\\\ \\epsilon_n\n",
    "\\end{array}\\right] = \\epsilon' \\epsilon\n",
    "$$\n",
    "\n",
    "Therefore we can write the sum of the squared residuals as:\n",
    "\n",
    "### $$ \\epsilon' \\epsilon = (\\beta X - y)' (\\beta X - y) $$\n",
    "\n",
    "Which becomes:\n",
    "\n",
    "### $$ \\epsilon' \\epsilon = y'y - y'X\\beta - \\beta' X' y + \\beta' X' X \\beta $$\n",
    "\n",
    "**Step 4:** We want to find the coefficients at the loss function's minimum. In this case we can use calculus, taking the derivative with respect to the $\\beta$ vector:\n",
    "\n",
    "### $$ \\frac{\\partial \\epsilon' \\epsilon}{\\partial \\beta} = \n",
    "-2X'y + 2X'X\\beta$$\n",
    "\n",
    "Because we want to minimize the loss function and the loss function is convex, we set the derivative to zero and solve for the beta coefficient vector:\n",
    "\n",
    "### $$ 0 = -2X'y + 2X'X\\beta \\\\\n",
    "X'X\\beta = X'y \\\\\n",
    "\\beta = (X'X)^{-1}X'y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-data'></a>\n",
    "\n",
    "## Load the Simple Housing Data\n",
    "\n",
    "---\n",
    "\n",
    "This data set only has four columns. We can formulate simple regression problems with the data set to test our linear regression class down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = './datasets/housing-data.csv'\n",
    "house = pd.read_csv(house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classes-objects'></a>\n",
    "\n",
    "## Classes and Objects\n",
    "\n",
    "---\n",
    "\n",
    "In Python, everything is an \"object\" of some type. This is the basis of what is known as **object-oriented programming (OOP)**.\n",
    "\n",
    "A *class* is a type of object. You can think of a class definition as a sort of blueprint that specifies the construction of a new object when instantiated.\n",
    "\n",
    "> **Note:** Knowing how to define and use classes is essential for programming with Python at an intermediate or advanced level. We will cover the basics here, which will help you understand how concepts like `LinearRegression` in scikit-learn work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='coding-lr'></a>\n",
    "\n",
    "## Coding our Own Version of the Scikit-Learn `LinearRegression` Class\n",
    "\n",
    "---\n",
    "\n",
    "By now you're familiar with the `LinearRegression` class in scikit-learn. We'll walk through the re-creation of this class (albeit a simplified version).\n",
    "\n",
    "\n",
    "<a id='starting-class'></a>\n",
    "### 1) Starting a basic Python class.\n",
    "\n",
    "Below is the beginning of our class blueprint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    # for non-static and non-class methods, self must be the first input\n",
    "    def __init__(self): # Method\n",
    "        self.coef_ = None # Attribute that saves the value of coefficients. Private attributes have trailing underscores\n",
    "        self.intercept_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a class instance (object)\n",
    "slr = SimpleLinearRegression()\n",
    "slr.coef_ == None # Should return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the components of the blueprint?\n",
    "\n",
    "**`class`**\n",
    "\n",
    "- `class` works like `def`, but instead of defining a function, it defines a class.\n",
    "\n",
    "**`object`**\n",
    "\n",
    "- In the parentheses of the `class` definition, `object` indicates that this class \"inherits\" from the `object` class. The `object` class is a very general, fundamental class in Python. Inheritance means that whatever properties and functions are part of the `object` class are passed down to our `SimpleLinearRegression` class.\n",
    "\n",
    "**`def __init__(self)`**\n",
    "\n",
    "- `def __init__(self):` is our class' initialization function. This function is called when you instantiate the class by typing `SimpleLinearRegression()`.\n",
    "\n",
    "**`self`**\n",
    "\n",
    "- `self` is the first argument to class definitions. It's a variable that refers to the **current instantiation of the class**. What does this mean? When you instantiate a class and assign it to a variable with `slr = SimpleLinearRegression()`, the `self` argument becomes a reference to the current instantiation of the class `slr`. Now, when you use a function that is part of the class, it knows to use that specific object's function. This allows you to have multiple instantiations of a class with the same function name.\n",
    "\n",
    "**class attributes**\n",
    "\n",
    "- `self.coef_` and `self.intercept_` are both \"attributes\" (variables) that are connected to the instantiation of the class. When `self` becomes `slr`, for example, the `self` becomes `slr` and `self.coef_` becomes `slr.coef`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inheritance example.\n",
    "\n",
    "# P - polymorphism (only relevant when static types are a thing)\n",
    "# I - inheritance\n",
    "# E - encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumbClass(object):\n",
    "    def __init__(self, set_variable=1):\n",
    "        self.variable = set_variable\n",
    "    \n",
    "    def multiply_variable(self, multiplier):\n",
    "        return(self.variable * multiplier)\n",
    "    \n",
    "class DumbChild(DumbClass):\n",
    "    # child class that inherits from parent (DumbClass)\n",
    "    def __init__(self, set_variable=2):\n",
    "        super().__init__(set_variable) # runs the init of parent\n",
    "    \n",
    "    def print_hello(self):\n",
    "        print(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 6\n",
      "3\n",
      "<__main__.DumbChild object at 0x1081d25c0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent = DumbClass(set_variable=2)\n",
    "print(parent.variable, parent.multiply_variable(3))\n",
    "\n",
    "child = DumbChild(set_variable=3)\n",
    "print(child.variable)\n",
    "child.print_hello()\n",
    "child.multiply_variable(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='class-function'></a>\n",
    "### 2) Adding a class function.\n",
    "\n",
    "Just like with `__init__`, we can add functions to a class.\n",
    "\n",
    "**Let's add a `fit()` method that will calculate the coefficients for a linear regression.**\n",
    "- The function should have arguments `self`, `X`, and `y`.\n",
    "- Use the linear algebra equations above to calculate the coefficients and intercept.\n",
    "- Assign the coefficients to `self.coef_` and the intercept to `self.intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # beta = (X'X)^-1 X' y\n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_XT = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_XT, y)\n",
    "        \n",
    "        self.coef_ = betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we assigned `self.coef_` inside of the `fit()` function.\n",
    "\n",
    "This will set the class attribute `self.coef_`, which can be accessed by _any other function in the class without passing it as an argument._\n",
    "\n",
    "You can also access it after instantiating the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='init-args'></a>\n",
    "### 3) Assigning attributes during instantiation.\n",
    "\n",
    "There's an issue here — we may pass an `X` matrix in without an intercept. \n",
    "\n",
    "**Add a keyword argument to the `__init__` function, which will specify whether or not the `X` matrix should have an  added intercept.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # beta = (X'X)^-1 X' y\n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_XT = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_XT, y)\n",
    "        \n",
    "        self.coef_ = betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, if we instantiate the class, it will assign `fit_intercept` to the class attribute `fit_intercept`. Try it out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "slr.fit_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='intercept-adder'></a>\n",
    "### 4) Include a function to add an intercept to the `X` matrix if necessary.\n",
    "\n",
    "This function will be called from inside the `fit` function and run conditionally on the value of `self.fit_intercept`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        \"\"\"Take X as input and return a matrix with column of ones added to the left\"\"\"\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate([intercept, X], axis=1)\n",
    "        return(X)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        # beta = (X'X)^-1 X' y\n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_XT = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_XT, y)\n",
    "        \n",
    "        self.intercept_ = betas[0]\n",
    "        self.coef_ = betas[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='instantiate'></a>\n",
    "### 5) Instantiate the class.\n",
    "\n",
    "At this point, we can try out our class. \n",
    "\n",
    "**Instantiate the class and try out the coefficient-fitting function on the housing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = house.price.values\n",
    "X = house[['sqft', 'bdrms', 'age']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "print(slr.fit_intercept)\n",
    "print(slr.coef_)\n",
    "print(slr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1600,    3,   28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[  139.33484671 -8621.47045953   -81.21787764]\n",
      "92451.62784164395\n"
     ]
    }
   ],
   "source": [
    "slr.fit(X, y)\n",
    "print(slr.fit_intercept)\n",
    "print(slr.coef_)\n",
    "print(slr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with scikit-learn's `LinearRegression` class, after fitting the model, we now have access to the assigned `coef_` and `intercept_` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='predict'></a>\n",
    "### 6) Add the `predict` function.\n",
    "\n",
    "Let's add some more of the class methods that are in the real `LinearRegression` class.\n",
    "\n",
    "**First, add the `predict` function. It will take a design matrix `X` and return predictions for those rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        \"\"\"Take X as input and return a matrix with column of ones added to the left\"\"\"\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate([intercept, X], axis=1)\n",
    "        return(X)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        # beta = (X'X)^-1 X' y\n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_XT = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_XT, y)\n",
    "        \n",
    "        self.intercept_ = betas[0]\n",
    "        self.coef_ = betas[1:]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # prediction = X beta\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        return(np.dot(X, np.concatenate(([self.intercept_], self.coef_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test out the `predict` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([354062.48251176, 287248.87062952, 397417.26195747, 268527.15386339,\n",
       "       469878.94531868, 329591.12619219, 279352.25678876, 260788.62369656,\n",
       "       257732.2546397 , 273535.20928732, 327706.82348284, 343064.02719228,\n",
       "       326275.2722563 , 669306.04311939, 238553.16519158, 372182.11686444,\n",
       "       254095.1761696 , 232470.09254391, 421084.27168899, 478584.0909595 ,\n",
       "       309218.30398827, 331856.66518254, 289024.47818101, 327036.16773894,\n",
       "       605675.92658069, 214982.47518854, 267382.10451866, 417491.20685022,\n",
       "       370849.7786572 , 431982.76030362, 328196.75492169, 222758.9147067 ,\n",
       "       336117.49247439, 498239.03279901, 308351.92433696, 262750.49730718,\n",
       "       237436.29823206, 352753.53862119, 639901.74497352, 355715.31585793,\n",
       "       303813.15674695, 375413.5419335 , 411008.87848961, 227616.47381753,\n",
       "       188236.72488687, 310815.93794646, 233313.64040447])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "slr.fit(X, y)\n",
    "slr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='score'></a>\n",
    "### 7) Add a `score` function.\n",
    "\n",
    "This will calculate the $R^2$ of your model on a provided `X` and `y`.\n",
    "\n",
    "> **Note:** You'll probably want to write a helper function to calculate the sum of the squared errors, as this will be run for both the baseline model and the regression model in order to calculate the $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='verify'></a>\n",
    "\n",
    "## Verify Your Class Against the Scikit-Learn `LinearRegression` Implementation\n",
    "\n",
    "---\n",
    "\n",
    "Our class should return the same results for the $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspection'></a>\n",
    "\n",
    "## Inspecting a Class\n",
    "\n",
    "---\n",
    "\n",
    "When we want to know more about a class object, we can use the \"inspect\" module. Specifically, the `inspect.getmembers()` function takes an instantiated class as an argument and returns it as an information dictionary.\n",
    "\n",
    "This help us know which attributes and methods are available and, basically, the blueprint of a class object in memory. Depending on the way the class was implemented, you can usually find useful information hiding inside of `slr.__class__.__dict__` (which can be easier to interpret). However, the \"right way\" is to use the \"inspect\" module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='special'></a>\n",
    "\n",
    "## Some Special Class Methods\n",
    "\n",
    "---\n",
    "\n",
    "|Method| Description|\n",
    "|--|--|\n",
    "|\\_\\_init\\_\\_ ( self [,args...] )| Constructor (with any optional arguments). Sample call: `obj = className(args)`.\n",
    "|\\_\\_del\\_\\_( self ) | Destructor; deletes an object. Sample call: `del obj`.\n",
    "|\\_\\_repr\\_\\_( self ) | Evaluable string representation. Sample call: `repr(obj)`.\n",
    "|\\_\\_str\\_\\_( self ) | Printable string representation. Sample call: `str(obj)`.\n",
    "|\\_\\_cmp\\_\\_ ( self, x ) | Object comparison. Sample call: `cmp(obj, x)`.\n",
    "\n",
    "The `__repr__` function reports back a description of what the class represents. You can basically do whatever you want with it, but its purpose is to convey something descriptive about your class.\n",
    "\n",
    "The `__del__` method is the bookend function of `__init__`. You can use it to run code once your class has executed. Generally it works well, but in practice there are a few considerations to keep in mind. Read more about safely using Python destructors [here](http://eli.thegreenplace.net/2009/06/12/safely-using-destructors-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
